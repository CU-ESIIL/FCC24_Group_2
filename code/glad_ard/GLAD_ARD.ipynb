{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "from distributed import LocalCluster\n",
    "from distributed import Client\n",
    "\n",
    "cluster = LocalCluster(n_workers=8, threads_per_worker=4)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "southern_rockies = gpd.read_file(\"/data-store/output/southern_rockies.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "# intersect with GLAD ARD Tiles\n",
    "ard_tiles = gpd.read_file(\"https://glad.umd.edu/users/Potapov/ARD/Global_ARD_tiles.zip\")\n",
    "relevant_ard_tiles = ard_tiles.clip(southern_rockies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_ard_tiles.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_ard_tiles[relevant_ard_tiles['TILE']==\"105W_39N\"].to_file(\"team2_aoi.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tiles = [\"105W_39N\"]\n",
    "start_year = 1997\n",
    "end_year = 2023\n",
    "start_codes = np.cumsum(np.repeat(23, end_year-start_year + 1)) + 392 - 23\n",
    "year_code_maps = {year: list(range(start, start + 23)) for year, start in  zip(range(start_year, end_year+1), start_codes)}\n",
    "\n",
    "pattern = \"https://glad.umd.edu/dataset/glad_ard2/{lat}/{tile}/{period}.tif\"\n",
    "\n",
    "rows = []\n",
    "for tile in tiles:\n",
    "    for year, year_codes in year_code_maps.items():\n",
    "        for code in year_codes:\n",
    "            rows.append((tile, year, code, pattern.format(lat=tile.split(\"_\")[1], tile=tile, period=code)))\n",
    "\n",
    "ard_assets = pd.DataFrame(rows, columns=['tile','year','16-day-code','url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then use aria2 to download the files from the server over http e.g. \n",
    "```\n",
    "conda install ariac\n",
    "aria2c -i flist.txt -j 8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "import glob\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"data/*.tif\")\n",
    "files.sort(key = lambda x: int(x.split(\"/\")[1].split(\".\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_code_to_year = {}\n",
    "\n",
    "for key, values in year_code_maps.items():\n",
    "    for value in values:\n",
    "        reverse_code_to_year[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = []\n",
    "for f in files:\n",
    "    time_code = int(f.split(\"/\")[1].split(\".\")[0])\n",
    "    year = reverse_code_to_year[time_code]\n",
    "    dset = rioxarray.open_rasterio(f, chunks={\"x\": 1024, \"y\": 1024})\n",
    "    # just use year information for now\n",
    "    dset = dset.expand_dims(\"time\")\n",
    "    dset = dset.assign_coords(coords={'time': [datetime(year=year, month=1, day=1)]})\n",
    "    dsets.append(dset)\n",
    "dset = xr.concat(dsets, dim=\"time\")\n",
    "\n",
    "# simplest QF flag imagineable\n",
    "filtered = dset.where(dset.sel(band=8) == 1)\n",
    "\n",
    "# median composition over each year\n",
    "r = filtered.resample(time=\"1y\").median()\n",
    "\n",
    "# unify chunks\n",
    "r = r.chunk({\"x\":1024, \"y\": 1024})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# took 60 mins\n",
    "r.to_zarr(\"105W_39N_annual_median_composite.zarr\", mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from geogif import gif\n",
    "\n",
    "dset = xr.open_zarr(\"105W_39N_annual_median_composite.zarr\")\n",
    "dset[[3,2,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codefest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
